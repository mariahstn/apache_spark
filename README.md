# Data Processing using Apache Spark
*Disclaimer: this notebook is created for academic purposes*

We will be using Apache Spark environment for data generation, manipulation, and exploration.

**Summary**
1. Spark environment preparation
2. Existing data extraction, exploration, and data loading into Spark from CSV
3. Relational database schema and DDL design
4. Database deployment into a suitable relational database
5. New sample (fake) data generation based on the designed schema 
6. Sample data loading to the database using Apache Spark
7. DataFrames serialisation into Apache Parquet format
8. Data loading to DataFrames for further use 
